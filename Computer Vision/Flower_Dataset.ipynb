{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWyLiSkGPsrQdcUSIOAXDw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShyamSundhar1411/My-ML-Notebooks/blob/master/Computer%20Vision/Flower_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing Dataset"
      ],
      "metadata": {
        "id": "9HznCC5_SFJG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rMxMS6dAPx2C"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp4MIsRYP2wQ",
        "outputId": "1f156743-c96e-4160-95bc-18ccac7e1702"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-24 15:35:28--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-01-24 15:35:28 (79.8 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from helper_functions import create_tensorboard_callback,plot_loss_curves,unzip_data,walk_through_dir"
      ],
      "metadata": {
        "id": "Od2lsfn3QFgr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_h0pzaMQMWs",
        "outputId": "388ea6bd-2257-4cfb-93c2-bd5083518f2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.8/dist-packages (4.8.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (3.19.6)\n",
            "Requirement already satisfied: etils[enp,epath]>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.25.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (4.64.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (5.10.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (5.4.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.21.6)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.10.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.3.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.3.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (7.1.2)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.12.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (2.2.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (1.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from tensorflow-datasets) (0.1.8)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.11.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->tensorflow-datasets) (2.10)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-metadata->tensorflow-datasets) (1.58.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "archive = tf.keras.utils.get_file(origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(archive).with_suffix('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDPkABjEQSOY",
        "outputId": "2a8255e3-cff4-43d8-ec36-2f520b1b6631"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 6s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVQEmhJ-QXMx",
        "outputId": "bf7abe61-a095-405c-be2e-2c47f7a879fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/root/.keras/datasets/flower_photos')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Setting Up Data Loaders"
      ],
      "metadata": {
        "id": "2YatF1sXcZrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(data_dir,label_mode = \"categorical\",image_size = (224,224),validation_split = 0.2,subset = \"training\",seed = 42)\n",
        "test_dataset = image_dataset_from_directory(data_dir,label_mode = \"categorical\",image_size = (224,224),validation_split = 0.2,subset = \"validation\",seed = 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n6ORndkQmvf",
        "outputId": "c8621344-2936-43bd-ec2d-c43feae9a64c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_dataset.class_names"
      ],
      "metadata": {
        "id": "dBokrXWrQtSU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Data Augmentation"
      ],
      "metadata": {
        "id": "aqHSn_msctcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\",input_shape=(224, 224, 3)),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomWidth(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.Rescaling(1./255),\n",
        "    \n",
        "])"
      ],
      "metadata": {
        "id": "WGuy4CTGSDsz"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Model 0 Simple Model"
      ],
      "metadata": {
        "id": "EeQVMc13R0mb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path =\"model_0_weight_checkpoints/checkpoint.ckpt\"\n",
        "     \n",
        "checkpoint_call_back = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    save_weights_only = True,\n",
        "    save_best_only = True,\n",
        "    save_freq = \"epoch\"\n",
        ")"
      ],
      "metadata": {
        "id": "2SFJAx3kXr2g"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0 = tf.keras.Sequential([\n",
        "    data_augmentation,\n",
        "    tf.keras.layers.Conv2D(\n",
        "        filters = 32,\n",
        "        kernel_size = 3,\n",
        "        strides  = (1,1),\n",
        "        activation = \"relu\",name = \"input_layer\"\n",
        "        ),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        32,3,activation = \"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        32,3,activation = \"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.MaxPool2D(2),\n",
        "    tf.keras.layers.Conv2D(\n",
        "        32,3,activation = \"relu\"\n",
        "    ),\n",
        "    tf.keras.layers.GlobalMaxPool2D(),\n",
        "    tf.keras.layers.Dense(len(class_names),activation = \"softmax\",name = \"output_layer\"),\n",
        "\n",
        "])\n",
        "model_0.compile(loss = \"categorical_crossentropy\",metrics = [\"accuracy\"],optimizer = \"adam\")"
      ],
      "metadata": {
        "id": "UYw7P9zYSeYf"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_0 = model_0.fit(\n",
        "    train_dataset,epochs = 5,\n",
        "    steps_per_epoch = len(train_dataset),\n",
        "    validation_data = test_dataset,\n",
        "    validation_steps = len(test_dataset),\n",
        "    callbacks = [checkpoint_call_back]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFgtDYB1Yxwk",
        "outputId": "17b954ec-723d-4bdf-c3be-934a3dcc757a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "32/92 [=========>....................] - ETA: 1:14 - loss: 1.6092 - accuracy: 0.2246"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves"
      ],
      "metadata": {
        "id": "R0q50B3XZRMn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}